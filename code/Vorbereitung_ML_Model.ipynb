{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "588022fe",
   "metadata": {},
   "source": [
    "# Vorbereitung Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8312e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d34cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katharina\\AppData\\Local\\Temp\\ipykernel_10360\\3177194112.py:3: DtypeWarning: Columns (1,10,13,14,21,49,51,59,68,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Database = pd.read_csv('Daten_zusammen_final.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "#Daten einlesen\n",
    "os.chdir('C:/Users/Katharina/Desktop/Weiterbildung/Bootcamp/Bootcamp/Final_project/data')\n",
    "Database = pd.read_csv('Daten_zusammen_final.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7202707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variablen, die keine Rolle spielen entfernen\n",
    "DatM = Database.drop(['Actions', 'BuyTicketsUrl','Deadline','DefaultLocalTimeOffset','DefaultMatchFormat','DefaultTimeZone',\n",
    "'DispatchMethod', 'DispatchStatus', 'EarningsCurrencyCode', 'EndDateFederationQuota',\n",
    "'EntryPointsBaseDate','EntryPointsDayOffset', 'EntryPointsTemplateNo','EventAuxiliaryPersons',\n",
    "'EventLogos','IsFreeEntrance', 'IsVisManaged','Logos','MatchPointsMethod',\n",
    "'MaxRegisterFederation', 'MaxRegisterHost', 'MaxReserveTeams', 'MaxTeamsDispatchFederation',\n",
    "'MaxTeamsDispatchHost','MaxTeamsFederation','MaxTeamsHost','MaxTeamsMainDrawFederation', 'MaxTeamsMainDrawHost',\n",
    "'MinConfederationTeams', 'MinTeamsDispatchHost', 'NbTeamsFromQualification',\n",
    "'NbTeamsMainDraw', 'NbTeamsQualification','NbUploads', 'NbWildCards', 'NoTemplateEarnedPoints',\n",
    "'NoTemplatePrizeMoney','OrganizerCode', 'OrganizerType','Parameters', 'PreliminaryInquiryMainDraw',\n",
    "'PreliminaryInquiryQualification','SeedPointsBaseDate', 'SeedPointsDayOffset', 'SeedPointsTemplateNo',\n",
    "'StartDateFederationQuota', 'TechnicalEntryPointsTemplateNo','TechnicalSeedPointsTemplateNo',\n",
    "'Draws', 'check', 'check2', 'NoSet', 'point', 'latitude', 'longitude', 'timezone', 'UTC_offset_hours', \n",
    "'Zeitpunkt', 'index_col','source_row','time','Code','CountryCode','CountryName','DefaultCity','DefaultVenue',\n",
    "'EndDateMainDraw','EndDateQualification','FederationCode_x','Name_x','No','NoEvent','Season',\n",
    "'StartDate', 'StartDateMainDraw','StartDateQualification','Status', 'Title',\n",
    "'Version_x','WebSite','NoItem','No_x',\n",
    "'FederationCode_x',  'Gender_y', 'PlaysBeach', 'PlaysVolley', 'No_y','Version_y',\n",
    "'Rank','EarnedPointsTeam', '@MatchPointsA','@MatchPointsB','No','@Version', '@No'],axis=1)\n",
    "\n",
    "#'@PointsTeamASet1',\n",
    "#'@PointsTeamBSet1', '@PointsTeamASet2','@PointsTeamBSet2','@PointsTeamASet3', '@PointsTeamBSet3',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11221e5a",
   "metadata": {},
   "source": [
    "### Daten ohne richtige Statistikwerte entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00920eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_team_idx(group):\n",
    "    \"\"\"\n",
    "    Für jedes Match (Gruppe) werden:\n",
    "      - Bei den Spielerzeilen (ItemType = 30) der Team-Index anhand der existierenden FederationCode zugewiesen.\n",
    "        Die eindeutigen FederationCodes werden alphabetisch sortiert; \n",
    "        z. B. 'ABC' → 1, 'DEF' → 2.\n",
    "      - Bei den Teamzeilen (ItemType = 11) wird der Team-Index entsprechend der Reihenfolge (aufsteigend nach dem Index)\n",
    "        zugewiesen.\n",
    "    \"\"\"\n",
    "    # Für Spieler: Filtern, sortieren und Mapping erstellen\n",
    "    players = group[group['ItemType'] == 30].copy()\n",
    "    unique_codes = sorted(players['FederationCode_y'].dropna().unique())\n",
    "    mapping = {code: i+1 for i, code in enumerate(unique_codes)}\n",
    "    \n",
    "    # Zuweisung des Team-Index zu Spielerzeilen\n",
    "    group.loc[group['ItemType'] == 30, 'team_idx'] = group.loc[group['ItemType'] == 30, 'FederationCode_y'].map(mapping)\n",
    "    \n",
    "    # Für Team-Zeilen (ItemType = 11): Zuweisung nach Reihenfolge (aufsteigend nach Index)\n",
    "    team_rows = group[group['ItemType'] == 11].copy().sort_index()\n",
    "    team_idxs = list(range(1, len(team_rows) + 1))\n",
    "    group.loc[group['ItemType'] == 11, 'team_idx'] = team_idxs\n",
    "    \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e706d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katharina\\AppData\\Local\\Temp\\ipykernel_10360\\2012731063.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_assigned = df.groupby('NoMatch', group_keys=False).apply(assign_team_idx)\n"
     ]
    }
   ],
   "source": [
    "df = DatM\n",
    "# Wende die Funktion pro Match an\n",
    "df_assigned = df.groupby('NoMatch', group_keys=False).apply(assign_team_idx)\n",
    "\n",
    "# Extrahiere die Teamzeilen (ItemType =11) mit MatchNo und team_idx; bei diesen Zeilen ist TeamFault gesetzt\n",
    "df_team = df_assigned[df_assigned['ItemType'] == 11][['NoMatch', 'team_idx', 'TeamFault','NoPlayer1', 'NoPlayer2']].drop_duplicates()\n",
    "\n",
    "# Extrahiere die Spielerzeilen (ItemType = 30) – hier ist FederationCode vorhanden\n",
    "df_players = df_assigned[df_assigned['ItemType'] == 30].copy()\n",
    "\n",
    "# Merge: Verbinde mittels MatchNo und team_idx die Spielerzeilen mit den Teamzeilen, um TeamFault an die Spieler zu hängen\n",
    "df_merged = pd.merge(df_players, df_team, on=['NoMatch', 'team_idx'], how='left', suffixes=('', '_team'))\n",
    "\n",
    "# Optional: Sortiere nach Index, um die ursprüngliche Reihenfolge beizubehalten\n",
    "df_merged.sort_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba3c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datensatz nach den Zeilen filtern, wo Statistikdaten vorhanden sind\n",
    "\n",
    "DatS = df_merged[df_merged['ServeTotal'] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e08ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatS.to_csv('DatenML_V1.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67eeadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/Katharina/Desktop/Weiterbildung/Bootcamp/Bootcamp/Final_project/data')\n",
    "DatS = pd.read_csv('DatenML_V1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32954a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assign_team_label(row):\n",
    "    # Lese den Teamnamen der aktuellen Zeile aus\n",
    "    team_name = row['TeamName']\n",
    "    # Zerlege den String in @TeamAName in einzelne Namen – Trimme Leerzeichen\n",
    "    team_a_names = [name.strip() for name in row['@TeamAName'].split('/')]\n",
    "    # Falls team_name in der Liste der TeamA-Namen enthalten ist, handelt es sich um Team A, ansonsten um Team B\n",
    "    return 'A' if team_name in team_a_names else 'B'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbdc87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatSS = DatS.copy()\n",
    "DatSS['TeamDesignation'] = DatSS.apply(assign_team_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "268bca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neue variante\n",
    "import pandas as pd\n",
    "\n",
    "def group_and_sum_with_second_names(df):\n",
    "    \"\"\"\n",
    "    Gruppiert den DataFrame nach 'NoMatch' und 'TeamDesignation'.\n",
    "    \n",
    "    - Für die in sum_cols definierten Spalten wird die Summe berechnet.\n",
    "    - Für alle übrigen Spalten wird der erste Eintrag übernommen.\n",
    "    - Für 'FirstName' und 'LastName' werden zusätzlich die jeweils\n",
    "      \"verlorenen\" Namen (also der zweite Wert in der Gruppe) in neuen\n",
    "      Spalten 'FirstName2' und 'LastName2' gespeichert.\n",
    "    \n",
    "    Voraussetzung: In jeder Gruppe gibt es mindestens zwei Zeilen.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Der Eingabe-Datensatz.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Der aggregierte DataFrame.\n",
    "    \"\"\"\n",
    "    # Spalten, die aufsummiert werden sollen\n",
    "    sum_cols = [\n",
    "        'SpikeFault', 'SpikePoint', 'ServeFault', 'ServePoint',\n",
    "        'ServeTotal', 'BlockPoint', 'BlockTotal', 'DigTotal',\n",
    "        'NoMatch', 'PointTotal', 'ReceptionFault', 'SpikeTotal'\n",
    "    ]\n",
    "    # Gruppenschlüssel\n",
    "    group_keys = ['NoMatch', 'TeamDesignation']\n",
    "    \n",
    "    # Erstelle das Aggregations-Dictionary\n",
    "    agg_dict = {}\n",
    "    for col in df.columns:\n",
    "        if col in group_keys:\n",
    "            agg_dict[col] = 'first'\n",
    "        elif col in sum_cols:\n",
    "            agg_dict[col] = 'sum'\n",
    "        # Für FirstName und LastName legen wir zuerst 'first' fest\n",
    "        # und ermitteln später den \"zweiten\" Namen (der sonst verloren ginge)\n",
    "        elif col in ['FirstName', 'LastName']:\n",
    "            agg_dict[col] = 'first'\n",
    "        else:\n",
    "            agg_dict[col] = 'first'\n",
    "    \n",
    "    # Gruppierung des DataFrames\n",
    "    df_grouped = df.groupby(group_keys, as_index=False).agg(agg_dict)\n",
    "    \n",
    "    # Hilfsfunktion, um den zweiten Wert einer Gruppe zu erhalten\n",
    "    def get_second(x):\n",
    "        \"\"\"Gibt den zweiten Eintrag von x zurück, falls vorhanden, ansonsten None.\"\"\"\n",
    "        if len(x) > 1:\n",
    "            return x.iloc[1]\n",
    "        return None\n",
    "    \n",
    "    # Ermittle für jede Gruppe den zweiten FirstName und LastName\n",
    "    second_names = df.groupby(group_keys).agg({\n",
    "        'FirstName': get_second,\n",
    "        'LastName': get_second\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Umbenennen der Spalten auf FirstName2 und LastName2\n",
    "    second_names = second_names.rename(columns={'FirstName': 'FirstName2', 'LastName': 'LastName2'})\n",
    "    \n",
    "    # Zusammenführen der aggregierten Daten mit den \"zweiten\" Namen\n",
    "    df_final = pd.merge(df_grouped, second_names, on=group_keys, how='left')\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# Beispielaufruf:\n",
    "df_aggregated = group_and_sum_with_second_names(DatSS)\n",
    "# print(df_aggregated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pandas as pd\n",
    "# test = DatSS.copy()\n",
    "\n",
    "\n",
    "# # 1. Definiere die Spalten, die aufsummiert werden sollen:\n",
    "# sum_cols = ['SpikeFault', 'SpikePoint', 'ServeFault', 'ServePoint',\n",
    "#             'ServeTotal', 'BlockPoint', 'BlockTotal', 'DigTotal',\n",
    "#             'NoMatch', 'PointTotal', 'ReceptionFault', 'SpikeTotal']\n",
    "\n",
    "# # 2. Bestimme die Gruppenschlüssel – hier gehen wir davon aus, dass pro Team \n",
    "# # (innerhalb eines Matches) über die Kombination 'MatchNo' und 'team_idx' eindeutig gearbeitet wird.\n",
    "# group_keys = ['NoMatch', 'team_idx']\n",
    "\n",
    "# # 3. Hilfsfunktion, um für Spalten, bei denen es individuelle Werte gibt, diese zusammenzuführen.\n",
    "# def combine_if_diff(x):\n",
    "#     # Entferne leere Werte und bestimme die eindeutigen Einträge\n",
    "#     uniques = x.dropna().unique()\n",
    "#     if len(uniques) == 0:\n",
    "#         return None\n",
    "#     elif len(uniques) == 1:\n",
    "#         return uniques[0]\n",
    "#     else:\n",
    "#         # Wenn es mehrere unterschiedliche Werte gibt, verbinde sie per \" / \"\n",
    "#         return \" / \".join(map(str, uniques))\n",
    "\n",
    "# # 4. Erzeuge das Aggregations-Dictionary\n",
    "# agg_dict = {}\n",
    "# for col in test.columns:\n",
    "#     if col in group_keys:\n",
    "#         agg_dict[col] = 'first'\n",
    "#     elif col in sum_cols:\n",
    "#         agg_dict[col] = 'sum'\n",
    "#     else:\n",
    "#         # Je nach Spalte möchtest du eventuell, dass identische Werte einfach übernommen werden.\n",
    "#         # Sind sie unterschiedlich (z. B. FirstName, LastName usw.), werden sie verbunden.\n",
    "#         agg_dict[col] = combine_if_diff\n",
    "\n",
    "# # 5. Führe die Gruppierung durch:\n",
    "# df_team_aggregated = test.groupby(group_keys, as_index=False).agg(agg_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baee87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#variante 3\n",
    "import re\n",
    "\n",
    "df = df_aggregated.copy()\n",
    "\n",
    "# 1. Dynamisch alle Set-Nummern finden\n",
    "# Wir suchen in den Spalten nach Mustern wie \"@PointsTeamASetX\" und extrahieren X\n",
    "set_nums = sorted(\n",
    "    {int(re.search(r'@PointsTeamASet(\\d+)', col).group(1))\n",
    "     for col in df.columns\n",
    "     if re.match(r'@PointsTeamASet\\d+', col)}\n",
    ")\n",
    "\n",
    "# 2. Gewinn-Indikatoren für jedes Team und jedes Set erstellen\n",
    "for i in set_nums:\n",
    "    df[f'win_set{i}_A'] = (df[f'@PointsTeamASet{i}'] > df[f'@PointsTeamBSet{i}']).astype(int)\n",
    "    df[f'win_set{i}_B'] = (df[f'@PointsTeamBSet{i}'] > df[f'@PointsTeamASet{i}']).astype(int)\n",
    "\n",
    "# 3. Summiere die gewonnenen Sätze je Match und bestimme den Gewinner\n",
    "setA_cols = [f'win_set{i}_A' for i in set_nums]\n",
    "setB_cols = [f'win_set{i}_B' for i in set_nums]\n",
    "\n",
    "match_totals = (\n",
    "    df\n",
    "    .groupby('NoMatch')[setA_cols + setB_cols]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "match_totals['match_winner'] = match_totals.apply(\n",
    "    lambda row: 'A' if row[setA_cols].sum() > row[setB_cols].sum()\n",
    "                else ('B' if row[setB_cols].sum() > row[setA_cols].sum()\n",
    "                      else pd.NA),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 4. Merge und match_win erzeugen\n",
    "df = df.merge(\n",
    "    match_totals[['NoMatch', 'match_winner']],\n",
    "    on='NoMatch',\n",
    "    how='left'\n",
    ")\n",
    "df['match_win'] = (df['TeamDesignation'] == df['match_winner']).astype(int)\n",
    "\n",
    "# 5. Aufräumen\n",
    "df_final3 = df.drop(columns=setA_cols + setB_cols + ['match_winner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56c1cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final3.to_csv('Dat_Fin_win.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc9ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/Katharina/Desktop/Weiterbildung/Bootcamp/Bootcamp/Final_project/data')\n",
    "\n",
    "df_final3 = pd.read_csv('Dat_Fin_win.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b008329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender_x', 'Type', 'ItemType', 'SpikeFault', 'SpikePoint',\n",
       "       'ServeFault', 'ServePoint', 'ServeTotal', 'BlockPoint', 'BlockTotal',\n",
       "       'DigTotal', 'NoMatch', 'PointTotal', 'ReceptionFault', 'SpikeTotal',\n",
       "       'TeamFault', 'FederationCode_y', 'FirstName', 'LastName', 'TeamName',\n",
       "       'TournamentNo', 'NoPlayer1', 'NoPlayer2', 'Name_y', '@NoInTournament',\n",
       "       '@LocalDate', '@LocalTime', '@TeamAName', '@TeamBName', '@Court',\n",
       "       '@PointsTeamASet1', '@PointsTeamBSet1', '@PointsTeamASet2',\n",
       "       '@PointsTeamBSet2', '@PointsTeamASet3', '@PointsTeamBSet3',\n",
       "       '@DurationSet1', '@DurationSet2', '@DurationSet3', 'ID_row',\n",
       "       'ID_DefaultCity', 'temperature_2m', 'precipitation', 'wind_speed_10m',\n",
       "       'rain', 'wind_gusts_10m', 'team_idx', 'TeamFault_team',\n",
       "       'NoPlayer1_team', 'NoPlayer2_team', 'TeamDesignation', 'FirstName2',\n",
       "       'LastName2', 'match_win'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60d4e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variablen entfernen\n",
    "DatS1 = df_final3[['Gender_x','Type', 'TournamentNo', 'SpikeFault', 'SpikePoint', 'ServeFault',\n",
    "       'ServePoint', 'ServeTotal', 'BlockPoint', 'BlockTotal', 'DigTotal',\n",
    "        'ReceptionFault', 'SpikeTotal','@LocalDate',\n",
    "       '@LocalTime', 'FederationCode_y', 'FirstName', 'LastName','FirstName2','LastName2', '@TeamAName', '@TeamBName', 'NoPlayer1_team', 'NoPlayer2_team', '@PointsTeamASet1',\n",
    "       '@PointsTeamBSet1', '@PointsTeamASet2','@PointsTeamBSet2','@PointsTeamASet3','@PointsTeamBSet3',\n",
    "        '@DurationSet1',\n",
    "       '@DurationSet2', '@DurationSet3', 'temperature_2m',\n",
    "       'precipitation', 'wind_speed_10m', 'rain', 'wind_gusts_10m','TeamFault_team',  'match_win', 'TeamDesignation']]\n",
    "\n",
    "       # 'total_A', 'total_B',.-> wo sind die variablen her? das ist die Anzahl der Sätze, die ein Team gewonnen hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11d441d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatS2 = DatS1.dropna(subset=['temperature_2m', 'precipitation', 'wind_speed_10m', 'rain', 'wind_gusts_10m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fd543be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatS2.to_csv('DatenML_V2_relCol_ZusatzType.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatS3 = DatS2.copy()\n",
    "import numpy as np\n",
    "\n",
    "# Neue Spalte basierend auf TeamDesignation erstellen:\n",
    "DatS3[\"TeamNameFull\"] = np.where(DatS3[\"TeamDesignation\"] == \"A\", DatS3[\"@TeamAName\"], DatS3[\"@TeamBName\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c0be5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatS3.to_csv('TeamStatistik1.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten anpassen. Team muss immer gleich heißen und nicht einmal andere Reihenfolge\n",
    "#DatenML_V2_relCol_ZusatzType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9ae94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('TeamStatistik1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import unicodedata\n",
    "#es ist der Fall das Teams doppelt vorkommen, weil die Namen vertauscht sind\n",
    "def normalize_string(s):\n",
    "    \"\"\"\n",
    "    Entfernt diakritische Zeichen aus einem String, sodass z.B. \"Å\" zu \"A\" wird.\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "def standardize_names(name_str):\n",
    "    \"\"\"\n",
    "    Teilt den Eingabestring, der zwei Namen enthält (getrennt durch '/'),\n",
    "    entfernt überflüssige Leerzeichen und sortiert die beiden Namen anhand des\n",
    "    normalisierten Strings, sodass immer der Name zuerst steht, der alphabetisch\n",
    "    (unter Ignorieren von Sonderzeichen) früher kommt.\n",
    "    \"\"\"\n",
    "    # Teile den String anhand von '/' und entferne eventuelle Leerzeichen\n",
    "    parts = [part.strip() for part in name_str.split('/')]\n",
    "    \n",
    "    # Sortiere die beiden Namen. Dabei wird der normalisierte, kleingeschriebene Wert \n",
    "    # als Schlüssel verwendet, sodass z.B. \"Åhman\" (-> \"ahman\") richtiger sortiert wird.\n",
    "    parts_sorted = sorted(parts, key=lambda x: normalize_string(x).lower())\n",
    "    \n",
    "    # Füge die sortierten Namen wieder mit '/' zusammen\n",
    "    return \"/\".join(parts_sorted)\n",
    "\n",
    "\n",
    "# Wende die Funktion auf die Spalte \"@Namen\" an und speichere das Ergebnis in der neuen Spalte \"Standard_Namen\"\n",
    "BeachTeams1 = test.copy()\n",
    "BeachTeams1[\"Standard_Namen\"] = BeachTeams1[\"TeamNameFull\"].apply(standardize_names)\n",
    "\n",
    "def reorder_player_numbers(row):\n",
    "    \"\"\"\n",
    "    Vergleicht den ursprünglichen Namen (gesplittet in zwei Teile) mit der \n",
    "    alphabetisch sortierten Version. Stimmen sie nicht überein, wird angenommen,\n",
    "    dass auch die Player-Daten vertauscht wurden – und es werden die zugehörigen\n",
    "    numerischen Werte getauscht.\n",
    "    \"\"\"\n",
    "    # Die ursprüngliche Reihenfolge aus der Spalte '@Namen'\n",
    "    unsorted_names = [name.strip() for name in row[\"TeamNameFull\"].split('/')]\n",
    "    # Berechne die standardisierte (sortierte) Reihenfolge:\n",
    "    sorted_names = sorted(unsorted_names, key=lambda x: normalize_string(x).lower())\n",
    "    \n",
    "    # Falls die Reihenfolge nicht gleich ist, tausche die zugehörigen numerischen Spalten:\n",
    "    if unsorted_names != sorted_names:\n",
    "        row[\"NoPlayer1_team\"], row[\"NoPlayer2_team\"] = row[\"@NoPlayer2\"], row[\"@NoPlayer1\"]\n",
    "\n",
    "        # Falls weitere Spalten (z.B. playerbezogene Positionen) in diesem Zusammenhang,\n",
    "        # können diese ebenfalls getauscht werden.\n",
    "    return row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
